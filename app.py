# ==========================================================
# TK ì—˜ë¦¬ë² ì´í„° í†µí•© ê¸°ìˆ ì§€ì› AI
# OCR ë¯¸ì‚¬ìš© / íšŒë¡œë„ í…ìŠ¤íŠ¸ ì„¤ëª… ê¸°ë°˜
# ëª¨ë°”ì¼ Â· Cloud ì™„ì „ ëŒ€ì‘
# ==========================================================

import streamlit as st
from openai import OpenAI
import os
import fitz
import re
import math

# ==========================================================
# OpenAI
# ==========================================================
client = OpenAI()

# ==========================================================
# ë©”ë‰´ì–¼ ë¡œë”© (PDF + TXT + MD)
# ==========================================================
@st.cache_data(show_spinner=True)
def load_manual_chunks():
    manuals_dir = "manuals"
    chunks = []

    if not os.path.exists(manuals_dir):
        return chunks

    for file in os.listdir(manuals_dir):
        path = os.path.join(manuals_dir, file)

        # PDF (í…ìŠ¤íŠ¸ë§Œ)
        if file.lower().endswith(".pdf"):
            doc = fitz.open(path)
            for page_no, page in enumerate(doc, start=1):
                text = page.get_text().strip()
                if not text:
                    continue

                paragraphs = [
                    p.strip()
                    for p in text.split("\n\n")
                    if len(p.strip()) > 40
                ]

                for para in paragraphs:
                    chunks.append({
                        "file": file,
                        "page": page_no,
                        "text": para
                    })

        # TXT / MD (íšŒë¡œë„ ì„¤ëª…ìš©)
        elif file.lower().endswith((".txt", ".md")):
            with open(path, "r", encoding="utf-8") as f:
                content = f.read()

            paragraphs = [
                p.strip()
                for p in content.split("\n\n")
                if len(p.strip()) > 30
            ]

            for para in paragraphs:
                chunks.append({
                    "file": file,
                    "page": "N/A",
                    "text": para
                })

    return chunks

MANUAL_CHUNKS = load_manual_chunks()

# ==========================================================
# ì§ˆë¬¸ â†” ë¬¸ë‹¨ ìœ ì‚¬ë„
# ==========================================================
def similarity(q, t):
    q_set = set(re.findall(r"[a-zA-Z0-9ê°€-í£]+", q.lower()))
    t_set = set(re.findall(r"[a-zA-Z0-9ê°€-í£]+", t.lower()))
    if not q_set or not t_set:
        return 0
    return len(q_set & t_set) / math.sqrt(len(q_set) * len(t_set))

def retrieve_context(question, top_k=6):
    scored = []
    for c in MANUAL_CHUNKS:
        s = similarity(question, c["text"])
        if s > 0:
            scored.append((s, c))
    scored.sort(reverse=True, key=lambda x: x[0])
    return [c for _, c in scored[:top_k]]

# ==========================================================
# UI
# ==========================================================
st.set_page_config("TK Elevator ê¸°ìˆ ì§€ì› AI", layout="wide")
st.title("ğŸ› ï¸ TK ì—˜ë¦¬ë² ì´í„° í†µí•© ê¸°ìˆ ì§€ì› AI")

st.markdown("""
âœ” ë©”ë‰´ì–¼ ê¸°ë°˜  
âœ” OCR ë¯¸ì‚¬ìš©  
âœ” íšŒë¡œë„ ì„¤ëª… í…ìŠ¤íŠ¸ ì§€ì›  
âœ” ëª¨ë°”ì¼ 5G/LTE ì‚¬ìš© ê°€ëŠ¥  
âœ” ì¶”ì¸¡ ê¸ˆì§€
""")

question = st.text_input("ê³ ì¥ ì¦ìƒ ë˜ëŠ” ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")

# ==========================================================
# ì§ˆë¬¸ ì²˜ë¦¬
# ==========================================================
if st.button("ì§ˆë¬¸í•˜ê¸°") and question:
    if not MANUAL_CHUNKS:
        st.error("ë©”ë‰´ì–¼ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    else:
        contexts = retrieve_context(question)

        if not contexts:
            st.warning("ë©”ë‰´ì–¼ ê¸°ì¤€ í™•ì¸ ë¶ˆê°€")
        else:
            context_text = ""
            for c in contexts:
                context_text += f"\n[{c['file']} - {c['page']}]\n{c['text']}\n"

            response = client.responses.create(
                model="gpt-4.1-mini",
                input=[
                    {
                        "role": "system",
                        "content": f"""
ë„ˆëŠ” TK ì—˜ë¦¬ë² ì´í„° í˜„ì¥ ê¸°ìˆ ì§€ì› AIë‹¤.

ê·œì¹™:
- ë©”ë‰´ì–¼/íšŒë¡œ ì„¤ëª… íŒŒì¼ì— ìˆëŠ” ë‚´ìš©ë§Œ ë‹µí•œë‹¤
- ì¶”ì¸¡, ì¼ë°˜ë¡ , ê²½í—˜ë‹´ ìƒì„± ê¸ˆì§€
- ì—†ìœ¼ë©´ "ë©”ë‰´ì–¼ ê¸°ì¤€ í™•ì¸ ë¶ˆê°€"ë¼ê³  ë§í•œë‹¤
- ì ê²€ ì ˆì°¨ëŠ” ë‹¨ê³„ë³„ë¡œ ì œì‹œ
- ì•ˆì „ ê´€ë ¨ ë‚´ìš©ì€ ë°˜ë“œì‹œ ì£¼ì˜ ë¬¸êµ¬ í¬í•¨

[ì°¸ì¡° ë¬¸ì„œ]
{context_text}
"""
                    },
                    {
                        "role": "user",
                        "content": question
                    }
                ]
            )

            st.success(response.output_text)
