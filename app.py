# ==========================================================
# TK ì—˜ë¦¬ë² ì´í„° í†µí•© ê¸°ìˆ ì§€ì› AI
# ë©”ë‰´ì–¼ ê¸°ë°˜ / OCR ì•ˆì „ ë¹„í™œì„±í™” (Streamlit Cloud ëŒ€ì‘)
# ==========================================================

import streamlit as st
from openai import OpenAI
import os
import fitz  # PyMuPDF
from PIL import Image
import io
import re
import math

# ==========================================================
# OpenAI
# ==========================================================
client = OpenAI()

# ==========================================================
# PDF â†’ í˜ì´ì§€ â†’ ë¬¸ë‹¨ ë‹¨ìœ„ ë¡œë“œ (í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©)
# ==========================================================
@st.cache_data(show_spinner=True)
def load_manual_chunks():
    manuals_dir = "manuals"
    chunks = []

    if not os.path.exists(manuals_dir):
        return chunks

    for pdf in os.listdir(manuals_dir):
        if not pdf.lower().endswith(".pdf"):
            continue

        doc = fitz.open(os.path.join(manuals_dir, pdf))

        for page_no, page in enumerate(doc, start=1):
            text = page.get_text().strip()

            # ğŸ”´ OCR ì™„ì „ ë¹„í™œì„±í™” (Cloud ì•ˆì •ì„±)
            if not text:
                continue

            paragraphs = [
                p.strip()
                for p in text.split("\n\n")
                if len(p.strip()) > 40
            ]

            for para in paragraphs:
                chunks.append({
                    "file": pdf,
                    "page": page_no,
                    "text": para
                })

    return chunks

MANUAL_CHUNKS = load_manual_chunks()

# ==========================================================
# ì§ˆë¬¸ â†” ë¬¸ë‹¨ ìœ ì‚¬ë„ ê³„ì‚°
# ==========================================================
def similarity(q, t):
    q_set = set(re.findall(r"[a-zA-Z0-9]+", q.lower()))
    t_set = set(re.findall(r"[a-zA-Z0-9]+", t.lower()))
    if not q_set or not t_set:
        return 0
    return len(q_set & t_set) / math.sqrt(len(q_set) * len(t_set))

def retrieve_context(question, top_k=6):
    scored = []
    for c in MANUAL_CHUNKS:
        s = similarity(question, c["text"])
        if s > 0:
            scored.append((s, c))
    scored.sort(reverse=True, key=lambda x: x[0])
    return [c for _, c in scored[:top_k]]

# ==========================================================
# UI
# ==========================================================
st.set_page_config("TK Elevator ê¸°ìˆ ì§€ì› AI", layout="wide")
st.title("ğŸ› ï¸ TK ì—˜ë¦¬ë² ì´í„° í†µí•© ê¸°ìˆ ì§€ì› AI")

st.markdown("""
âœ” ë©”ë‰´ì–¼ ê¸°ë°˜  
âœ” ì¶”ì¸¡ ê¸ˆì§€  
âœ” í…ìŠ¤íŠ¸ PDF ìµœì í™”  
âœ” Streamlit Cloud ì•ˆì • ë²„ì „
""")

question = st.text_input("ê³ ì¥ ì¦ìƒ ë˜ëŠ” ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")

# ==========================================================
# ì§ˆë¬¸ ì²˜ë¦¬
# ==========================================================
if st.button("ì§ˆë¬¸í•˜ê¸°") and question:
    if not MANUAL_CHUNKS:
        st.error("ë©”ë‰´ì–¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    else:
        contexts = retrieve_context(question)

        context_text = ""
        for c in contexts:
            context_text += f"\n[{c['file']} - page {c['page']}]\n{c['text']}\n"

        response = client.responses.create(
            model="gpt-4.1-mini",
            input=[
                {
                    "role": "system",
                    "content": f"""
ë„ˆëŠ” TK ì—˜ë¦¬ë² ì´í„° í˜„ì¥ ê¸°ìˆ ì§€ì› AIë‹¤.

ê·œì¹™:
- ë©”ë‰´ì–¼ì— ìˆëŠ” ë‚´ìš©ë§Œ ì„¤ëª…í•œë‹¤
- ì¶”ì¸¡, ì¼ë°˜í™”, ì„ì˜ í•´ì„ ê¸ˆì§€
- ì—†ìœ¼ë©´ 'ë©”ë‰´ì–¼ ê¸°ì¤€ í™•ì¸ ë¶ˆê°€'ë¼ê³  ëª…ì‹œ
- ì ê²€ì€ ë‹¨ê³„ë³„ë¡œ ì œì‹œ
- ì•ˆì „ ê´€ë ¨ ë‚´ìš©ì€ ë°˜ë“œì‹œ ì£¼ì˜ í‘œì‹œ

[ë©”ë‰´ì–¼ ë°œì·Œ]
{context_text}
"""
                },
                {
                    "role": "user",
                    "content": question
                }
            ]
        )

        st.success(response.output_text)
